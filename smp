# 概述
并行的常规做法是使用线程，但有很多性能但问题。seastar 使用了不同的模型。

## 背景
线程和进程是操作系统的概念。与拥有一个或少量固定数量的处理器不同，操作系统允许用户创建任意数量的虚拟处理器，并将这些虚拟处理器多路复用到物理处理器之上。 这些虚拟处理器称为线程（如果它们彼此共享内存）或进程（如果它们不共享）。

### thread-per-connection

最简单的线程方法是**每个连接一个线程**。 对于需要服务的每个连接，都会创建一个线程，在该线程中运行读取-处理-响应循环。 这种方法有很多问题，使它不能成为最简单的方式。

- 有了大量的连接，就会创建许多线程。 线程是重量级对象，因此分配其中许多会消耗资源（主要是内存）。
- 如果许多连接同时处于活动状态，则许多线程将同时运行。 操作系统将被迫在线程之间快速切换； 由于这是一项昂贵的操作，因此性能会下降。
- 很难保证事件的及时处理。 如果系统线程太多，可能都比较忙，系统可能无法及时调度服务我们事件的线程。 如果线程太少，它们可能都在 I/O 上被阻塞，因此即使处理器能力可用，系统也可能无法满足我们的请求。 设置正确数量的线程是一个难题。

### thread pools

因此，大多数线程应用程序现在使用**线程池**。 这样，大量连接在较少数量的线程（它们本身在许多处理器上多路复用）之上进行多路复用。 读取线程将等待连接变为活动状态，将其分配给线程池中的空闲线程，然后该线程将读取请求、处理它并做出响应。

然而，这些线程设计仍然存在性能问题：
- 连接之间共享的数据需要用到锁。 在最坏的情况下，锁会导致过多的上下文切换和停顿。 在最好的情况下，它们是昂贵的操作，并且在具有十几个或更多内核的大型机器上不能很好地**扩展**。
- 共享的可写数据将从多个内核上的线程访问。 这需要处理器将数据从一个处理器的**缓存拷贝**到另一个处理器，这个操作很慢。
- 在一个处理器上分配的数据可能在另一个处理器上访问，或在另一个处理器上释放。 对于今天的 NUMA 架构，这对内存访问时间造成了严重的罚时（imposes a severe penalty on memory access time），并减慢了内存分配器的速度。

## seastar 的做法
Seastar 使用分片或分区来管理多个核心（core）。不是每个内核与所有其他内核共同负责所有连接和所有数据，而是为每个内核指定分配一部分机器上的连接和数据。如果核心上的计算需要访问驻留在另一个核心上的数据，它必须显式地向远程核心**发送消息**，要求它读取或写入数据，并等待结果。

### 网络连接分区
为了给连接分区，seastar 自动在核心之间的划分连接。

它利用现代网络接口卡 (NIC) 的能力为每个内核提供数据包队列，并自动将数据包子集转移到这些队列。

因此，每个 seastar 核心都会收到所有连接的一部分，并且属于这些连接的所有数据包都由该核心处理。

### 划分数据

seastar无法自动分区数据。 用户必须选择一种分区方法并将处理转移到正确的核心。 一些分区策略包括：
- **Hashed key**：可以用k-v存储, 使用键的低位来选择核心（个人理解应该时取模，或者相与，和hashmap有点像）。 适用于有大量需要使用主键访问的对象的情况。
- 复制: 数据在所有内核之间复制。 读取从本地核心提供，而修改则广播到所有核心。 对于频繁读取的数据，很少写入的小到中等总容量的数据，这种策略很适用。

一类应用程序特别适合分区——横向扩展服务器类。 这些已经跨节点分区，因此内核之间的分区仅使用节点内部分片扩展模型。

## seastar 模型的优势

分片数据和网络有很多好处：
- 局部性：内核始终访问在同一内核上分配和操作的数据。 这有利于内存分配器、CPU 缓存和 NUMA 架构。
- 少锁：锁的需要大大减少——通常根本不需要锁定，因为对数据项的所有访问都是隐式串行（serialized）的。 当需要锁时（例如，当处理数据时需要 I/O 时），它是使用普通的处理器指令而不是串行化的原子读-修改-写指令来完成的。

## seastar 模型的缺点
不幸的是，分片並非沒有缺點：
- 并非所有应用程序都适合分片； 这些应用程序根本无法受益。
- 由于分区不均匀导致内核之间的不平衡会导致某些内核过载而其他内核相对空闲，从而浪费资源


# 补充知识
## SMP、NUMA、MPP体系结构介绍
目前的商用服务器大体可以分为三类，即对称多处理器结构 (SMP ： Symmetric Multi-Processor) ，非一致存储访问结构 (NUMA ： Non-Uniform Memory Access) ，以及海量并行处理结构 (MPP ： Massive Parallel Processing) 。它们的特征分别描述如下：

### 1. SMP(Symmetric Multi-Processor)

SMP (Symmetric Multi Processing),对称多处理系统内有许多紧耦合多处理器，在这样的系统中，所有的CPU共享全部资源，如总线，内存和I/O系统等，操作系统或管理[数据库](https://cloud.tencent.com/solution/database?from=10680)的复本只有一个，这种系统有一个最大的特点就是共享所有资源。多个CPU之间没有区别，平等地访问内存、外设、一个操作系统。操作系统管理着一个队列，每个处理器依次处理队列中的进程。如果两个处理器同时请求访问一个资源（例如同一段内存地址），由硬件、软件的锁机制去解决资源争用问题。

SMP 服务器的主要特征是共享，系统中所有资源 (CPU 、内存、 I/O 等 ) 都是共享的。也正是由于这种特征，导致了 SMP 服务器的主要问题，那就是它的扩展能力非常有限。对于 SMP 服务器而言，每一个共享的环节都可能造成 SMP 服务器扩展时的瓶颈，而最受限制的则是内存。由于每个 CPU 必须通过相同的内存总线访问相同的内存资源，因此随着 CPU 数量的增加，内存访问冲突将迅速增加，最终会造成 CPU 资源的浪费，使 CPU 性能的有效性大大降低。实验证明， SMP 服务器 CPU 利用率最好的情况是 2 至 4 个 CPU 。

### 2. NUMA(Non-Uniform Memory Access)

　　由于 SMP 在扩展能力上的限制，人们开始探究如何进行有效地扩展从而构建大型系统的技术， NUMA 就是这种努力下的结果之一。利用 NUMA 技术，可以把几十个 CPU( 甚至上百个 CPU) 组合在一个服务器内。

NUMA 服务器的基本特征是具有多个 CPU 模块，每个 CPU 模块由多个 CPU( 如 4 个 ) 组成，并且具有独立的本地内存、 I/O 槽口等。由于其节点之间可以通过互联模块 ( 如称为 Crossbar Switch) 进行连接和信息交互，因此每个 CPU 可以访问整个系统的内存 ( 这是 NUMA 系统与 MPP 系统的重要差别 ) 。显然，访问本地内存的速度将远远高于访问远地内存 ( 系统内其它节点的内存 ) 的速度，这也是非一致存储访问 NUMA 的由来。由于这个特点，为了更好地发挥系统性能，开发应用程序时需要尽量减少不同 CPU 模块之间的信息交互。

但 NUMA 技术同样有一定缺陷，由于访问远地内存的延时远远超过本地内存，因此当 CPU 数量增加时，系统性能无法线性增加。

### 3. MPP(Massive Parallel Processing)

　　和 NUMA 不同， MPP 提供了另外一种进行系统扩展的方式，它由多个 SMP 服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。其基本特征是由多个 SMP 服务器 ( 每个 SMP 服务器称节点 ) 通过节点互联网络连接而成，每个节点只访问自己的本地资源 ( 内存、存储等 ) ，是一种完全无共享 (Share Nothing) 结构，因而扩展能力最好，理论上其扩展无限制，目前的技术可实现 512 个节点互联，数千个 CPU 。


# 参考资料
[SMP、NUMA、MPP体系结构介绍 - 云+社区 - 腾讯云](https://cloud.tencent.com/developer/article/1527941)

[SMP · scylladb/seastar Wiki](https://github.com/scylladb/seastar/wiki/SMP)
